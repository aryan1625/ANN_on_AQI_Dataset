{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjOHv3VzpbTtQToCJN6gvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryan1625/ANN_on_AQI_Dataset/blob/main/exp6multiclasslabellingandAnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yOGQkP898GZS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aqi = pd.read_csv('https://archive.ics.uci.edu/static/public/360/data.csv')"
      ],
      "metadata": {
        "id": "99V8Z0xIoqY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aqi = aqi.drop(columns=['Date', 'Time','NMHC(GT)','PT08.S1(CO)','C6H6(GT)','PT08.S2(NMHC)','PT08.S3(NOx)','PT08.S4(NO2)','RH','T','AH','NOx(GT)'])"
      ],
      "metadata": {
        "id": "EHHCOn3xosce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateAQI(x1,x2,i):\n",
        "  AQI = 0\n",
        "  CO = 0\n",
        "  NO2 = 0\n",
        "  O3 = 0\n",
        "\n",
        "  a = x1['CO(GT)'][i]\n",
        "  b = x1['NO2(GT)'][i]\n",
        "  c = x1['PT08.S5(O3)'][i]\n",
        "  # x['aqi'] = val\n",
        "\n",
        "  if(a<=2):\n",
        "    CO = 1\n",
        "  elif(a<=4):\n",
        "    CO = 2\n",
        "  elif(a<=8):\n",
        "    CO = 3\n",
        "  elif(a<=30):\n",
        "    CO = 4\n",
        "  elif(a<=100):\n",
        "    CO = 5\n",
        "  else:\n",
        "    CO = 6\n",
        "\n",
        "\n",
        "  if(b<=25):\n",
        "    NO2 = 1\n",
        "  elif(b<=50):\n",
        "    NO2 = 2\n",
        "  elif(b<=100):\n",
        "    NO2 = 3\n",
        "  elif(b<=200):\n",
        "    NO2 = 4\n",
        "  elif(b<=400):\n",
        "    NO2 = 5\n",
        "  else:\n",
        "    NO2 = 6\n",
        "\n",
        "\n",
        "  if(c<=500):\n",
        "    O3 = 1\n",
        "  elif(c<=1000):\n",
        "    O3 = 2\n",
        "  elif(c<=1300):\n",
        "    O3 = 3\n",
        "  elif(c<=2400):\n",
        "    O3 = 4\n",
        "  elif(c<=3800):\n",
        "    O3 = 5\n",
        "  else:\n",
        "    O3 = 6\n",
        "  val = round((CO+NO2+O3)/3)\n",
        "\n",
        "  x2[i][2] = O3\n",
        "  x2[i][1] = NO2\n",
        "  x2[i][0] = CO\n",
        "  x2[i][3] = val\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mncIDQ-yow0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = aqi.shape[0]\n",
        "aqi2 = np.zeros((m, 4))\n",
        "# aqi.head()\n",
        "# print(aqi['aqi'])\n",
        "for i in range(m):\n",
        "  calculateAQI(aqi,aqi2,i)\n",
        "# print(aqi2)\n",
        "\n",
        "# # Apply the calculateAQI function to each row and unpack the returned values\n",
        "# X['CO(GT)'], X['NO2(GT)'], X['PT08.S5(O3)'], y = zip(*X.apply(calculateAQI, axis=1))\n",
        "\n",
        "# # Using .loc to update the DataFrame\n",
        "# aqi.loc[:, ['CO(GT)', 'NO2(GT)', 'PT08.S5(O3)', 'aqi']] = X\n",
        "\n",
        "# print(aqi.head())"
      ],
      "metadata": {
        "id": "p1z15JI-o2G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "# Assuming your dataset is stored in a CSV file named 'aqi_dataset.csv'\n",
        "# dataset = pd.read_csv('aqi_dataset.csv')\n",
        "\n",
        "# Splitting the dataset into independent variables (X) and dependent variable (y)\n",
        "X = aqi2[:, :-1]  # All rows, all columns except the last one\n",
        "y = aqi2[:, -1]   # All rows, only the last column\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "y_train = np.array(y_train).reshape(-1,1)\n",
        "y_test = np.array(y_test).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "RzFOPsIxo5Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.biases_input_hidden = np.random.randn(1, self.hidden_size)\n",
        "\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.biases_hidden_output = np.random.randn(1, self.output_size)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        # Input to hidden layer\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.biases_input_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "\n",
        "        # Hidden to output layer\n",
        "        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.biases_hidden_output\n",
        "        self.output = self.softmax(self.output_input)\n",
        "        # self.predictions = (np.argmax(self.output, axis=1) + 1)\n",
        "        max_index = np.argmax(self.output, axis=1)\n",
        "\n",
        "        # Create a one-hot encoded version of the predictions\n",
        "        self.predictions = np.zeros_like(self.output)\n",
        "        self.predictions[np.arange(len(self.output)), max_index] = 1\n",
        "        return self.predictions\n",
        "\n",
        "    def backward_pass(self, X, y, output, learning_rate):\n",
        "        # Calculate error\n",
        "        self.output_error = y - output\n",
        "\n",
        "        # Calculate gradients\n",
        "        self.output_delta = self.output_error\n",
        "        self.hidden_error = self.output_delta.dot(self.weights_hidden_output.T)\n",
        "        self.hidden_delta = self.hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(self.output_delta) * learning_rate\n",
        "        self.biases_hidden_output += np.sum(self.output_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "        self.weights_input_hidden += X.T.dot(self.hidden_delta) * learning_rate\n",
        "        self.biases_input_hidden += np.sum(self.hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward_pass(X)\n",
        "            self.backward_pass(X, y, output, learning_rate)\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean(np.square(y - output))\n",
        "                print(f\"Epoch {epoch}, Loss: {loss}\")\n"
      ],
      "metadata": {
        "id": "XIxlk9SPpAzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# One-hot encode y_train\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
        "print(y_test_encoded.shape)\n",
        "input_size = 3\n",
        "hidden_size = 10\n",
        "output_size = 5\n",
        "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "# print(X_train.shape)\n",
        "\n",
        "# Train the neural network\n",
        "nn.train(X_train, y_train_encoded, epochs=1000, learning_rate=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZcmGhQDqXOd",
        "outputId": "00cef50c-2619-420b-d958-a5b079493c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1872, 5)\n",
            "Epoch 0, Loss: 0.2776753507014028\n",
            "Epoch 100, Loss: 0.17042084168336674\n",
            "Epoch 200, Loss: 0.18752171008684035\n",
            "Epoch 300, Loss: 0.07086172344689379\n",
            "Epoch 400, Loss: 0.014375417501670007\n",
            "Epoch 500, Loss: 0.013092852371409485\n",
            "Epoch 600, Loss: 0.011436205744822979\n",
            "Epoch 700, Loss: 0.011169004676018704\n",
            "Epoch 800, Loss: 0.037942551770207084\n",
            "Epoch 900, Loss: 0.19617902471609885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Test the trained network\n",
        "# print(X_test)\n",
        "predictions = nn.forward_pass(X_test)  # No need to flatten\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert predictions to class labels\n",
        "# predicted_labels = np.round(predictions).astype(int)\n",
        "\n",
        "# Convert y_test to class labels\n",
        "# true_labels = y_test.astype(int)\n",
        "# print(y_test)\n",
        "true_labels = y_test_encoded\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(true_labels, predictions, average='weighted',zero_division=1)\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(true_labels, predictions, average='weighted',zero_division=1)\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predictions, average='weighted',zero_division=1)\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IgclFTvwjvI",
        "outputId": "5aedfcc3-c6f9-46db-c501-857213da662b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9786\n",
            "Precision: 0.9785\n",
            "Recall: 0.9786\n",
            "F1 Score: 0.9780\n"
          ]
        }
      ]
    }
  ]
}